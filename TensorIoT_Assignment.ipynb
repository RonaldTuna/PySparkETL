{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorIoT_Assignment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOQ88Cj3Myx36VMxnJqmJXA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RonaldTuna/TensorIoTAssignment/blob/main/TensorIoT_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEPS:**\n",
        "\n",
        "Download the data files from here - http://jmcauley.ucsd.edu/data/amazon/links.html\n",
        "\n",
        "Apache spark tools locally and necessary tools\n",
        "\n",
        "Download a review file with a million reviews\n",
        "\n",
        "Using Jupyter notebook create a program to read the million reviews and get the following\n",
        "\n",
        "transform date to MM-DD-YYYY format\n",
        "\n",
        "Save the data into a table (postgres/sql server)\n",
        "Save the output as a Parquet file\n",
        "\n",
        "\n",
        "Upload code to Github  and complete Readme.md which anyone can understand\n",
        "\n",
        "Send Github link to HR\n",
        "\n",
        "\n",
        "\n",
        "Skills Learning / Tools Used:\n",
        "\n",
        "    postgres\n",
        "    workbench/J\n",
        "    Jupyter notebook\n",
        "    Apache spark\n",
        "    Data frame transforms\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QFW_FbEwBco8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnebPMZQCD7S",
        "outputId": "d419ae54-0f14-4632-a5be-9576deaec72e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  %pyspark_version 3.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM-KAwZ9QPON",
        "outputId": "e9c9957f-08fe-4be8-a181-9ecce9d7643a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 33 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 43.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=28990b6609bd0880f545395342be1a9afdcdd0aab45c2d44e80ceebd010a4237\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install postgresql server\n",
        "!sudo apt-get -y -qq update\n",
        "!sudo apt-get -y -qq install postgresql\n",
        "!sudo service postgresql start\n",
        "\n",
        "# Setup a password `postgres` for username `postgres`\n",
        "!sudo -u postgres psql -U postgres -c \"ALTER USER postgres PASSWORD 'postgres';\"\n",
        "\n",
        "# Setup a database with name `reviews` to be used\n",
        "!sudo -u postgres psql -U postgres -c 'DROP DATABASE IF EXISTS reviews;'\n",
        "!sudo -u postgres psql -U postgres -c 'CREATE DATABASE reviews;'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y97SOEe-T3m5",
        "outputId": "764b63de-dd12-490a-fcd2-f4d8b89b4682"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Starting PostgreSQL 10 database server\n",
            "   ...done.\n",
            "ALTER ROLE\n",
            "NOTICE:  database \"reviews\" does not exist, skipping\n",
            "DROP DATABASE\n",
            "CREATE DATABASE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env TFIO_DEMO_DATABASE_NAME=reviews\n",
        "%env TFIO_DEMO_DATABASE_HOST=localhost\n",
        "%env TFIO_DEMO_DATABASE_PORT=5432\n",
        "%env TFIO_DEMO_DATABASE_USER=postgres\n",
        "%env TFIO_DEMO_DATABASE_PASS=postgres"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz_pVkrtUVx3",
        "outputId": "aa0704d1-42cb-4733-cf76-597855d810e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: TFIO_DEMO_DATABASE_NAME=reviews\n",
            "env: TFIO_DEMO_DATABASE_HOST=localhost\n",
            "env: TFIO_DEMO_DATABASE_PORT=5432\n",
            "env: TFIO_DEMO_DATABASE_USER=postgres\n",
            "env: TFIO_DEMO_DATABASE_PASS=postgres\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "hfHbDA6VNMyS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I downloaded the reviews for Android Applications, which contains 2,638,173 reviews.\n",
        "\n",
        "Load reviews into pyspark dataframe... or ADD?"
      ],
      "metadata": {
        "id": "HOwqW3QIW02K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"AmazonReviews\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()\n",
        "df = spark.read.json('/content/reviews_Apps_for_Android.json.gz')"
      ],
      "metadata": {
        "id": "HT5Ic1uRLO7W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform data from MM DD, YYYY to MM-DD-YYYY by using to_date function.\n",
        "\n",
        "Replace old column with new column containing reformatted dates."
      ],
      "metadata": {
        "id": "TmrF7VPqfN5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('newTime', to_date('reviewTime', format='MM d, yyyy'))\n",
        "df = df.drop(\"reviewTime\")\n",
        "df = df.withColumnRenamed(\"newTime\",\"reviewTime\")\n",
        "df.show()\n"
      ],
      "metadata": {
        "id": "F4HWmtstLPq0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save data into SQL table/server"
      ],
      "metadata": {
        "id": "Zc5zFRwLXDO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw5STubygVNZ",
        "outputId": "8042a68a-ff38-44c1-ed60-468e80366ee4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+-------+--------------------+--------------+--------------------+--------------------+--------------+----------+\n",
            "|      asin| helpful|overall|          reviewText|    reviewerID|        reviewerName|             summary|unixReviewTime|reviewTime|\n",
            "+----------+--------+-------+--------------------+--------------+--------------------+--------------------+--------------+----------+\n",
            "|B004A9SDD8|  [0, 0]|    5.0|Glad to finally s...| AUI0OLXAB3KKT|          A Customer|        Great app!!!|    1301184000|2011-03-27|\n",
            "|B004A9SDD8|[12, 14]|    5.0|this app works gr...|A1ZUSQ3TC3EC4C|           A. Lissak|        Kid loves it|    1321574400|2011-11-18|\n",
            "|B004A9SDD8|  [0, 0]|    4.0|We love these mon...| AC05OAXD72X1V|               Allie| Love these monkeys!|    1367366400|2013-05-01|\n",
            "|B004A9SDD8|  [0, 2]|    5.0|cannot get my kin...|A2RVMFOKBVM21I|     Amazon Customer|fun fun for toddlers|    1350172800|2012-10-14|\n",
            "|B004A9SDD8|  [1, 3]|    1.0|I start this app ...|A3NBSRGUWQGCMZ|     Amazon Customer|Might be great if...|    1300838400|2011-03-23|\n",
            "|B004A9SDD8|  [0, 0]|    5.0|Very engaging to ...|A2KTVCVZJ8GPD2|           A. Mclean|         Great video|    1393545600|2014-02-28|\n",
            "|B004A9SDD8|  [1, 2]|    3.0|My daughter loves...|A2I9RREBHMMPCJ|             AngelaM|great when it worked|    1305504000|2011-05-16|\n",
            "|B004A9SDD8|  [1, 1]|    3.0|Loves the song, s...|A1N4O8VOJZTDVB|      Annette Yancey|         Really cute|    1383350400|2013-11-02|\n",
            "|B004A9SDD8|  [0, 0]|    5.0|Oh, how my little...|A2HQWU6HUKIEC7|Audiobook lover \"...| 2-year-old loves it|    1323043200|2011-12-05|\n",
            "|B004A9SDD8|  [0, 0]|    5.0|I found this at a...|A1SXASF6GYG96I|       Barbara Gibbs|            Fun game|    1337558400|2012-05-21|\n",
            "|B004A9SDD8|  [3, 4]|    5.0|My 1 year old goe...|A2B54P9ZDYH167|Brooke Greenstree...|We love our Monkeys!|    1354752000|2012-12-06|\n",
            "|B004A9SDD8|  [0, 4]|    4.0|Works great on my...|A3Q5R6B7MW8F7Q|              Buck9s|A fun little inte...|    1300924800|2011-03-24|\n",
            "|B004A9SDD8|  [0, 0]|    5.0|This is great for...|A118ECNHF2OCUO|             Carl K.|               great|    1300838400|2011-03-23|\n",
            "|B004A9SDD8|  [0, 0]|    5.0|I haven't found m...|A2BAQGVVFURVDR|                  CB|Awesome game for ...|    1327276800|2012-01-23|\n",
            "|B004A9SDD8|  [1, 1]|    5.0|There are three d...| AFOFZDTX5UC6D|          C. Galindo|This is my grandd...|    1391212800|2014-02-01|\n",
            "|B004A9SDD8|  [0, 1]|    5.0|i downloaded this...|A1MBEM25C3QS5R|               cindy|           dr said??|    1357430400|2013-01-06|\n",
            "|B004A9SDD8|  [1, 1]|    5.0|As a Speech langu...|A2CEK8H02SS23S|           cin_sph66|My patients reque...|    1389916800|2014-01-17|\n",
            "|B004A9SDD8|  [0, 0]|    1.0|Thought it would ...|A1WWW804VWFAHH|          dave hagen|Instead it was ju...|    1404864000|2014-07-09|\n",
            "|B004A9SDD8|  [3, 3]|    5.0|This is absolutel...|A3E6DLEQCZKGDC|             Deborah|           Favorite!|    1377561600|2013-08-27|\n",
            "|B004A9SDD8|  [3, 4]|    1.0|I am so disappoin...| AVYKSESEMLPE3|             Donna S|   Very Disappointed|    1325894400|2012-01-07|\n",
            "+----------+--------+-------+--------------------+--------------+--------------------+--------------------+--------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UKc_WaYWLQUc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "021285bb-f8c5-4ef2-f748-8fba5f2fab10"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3b852d5016e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnewDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'newDF' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save data into SQL table/server\n",
        "Save file as parquet file.\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "WSNkbzO6XHkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.parquet(\"Amazon_reviews.parquet\")"
      ],
      "metadata": {
        "id": "iTpRSGiNLRFN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}